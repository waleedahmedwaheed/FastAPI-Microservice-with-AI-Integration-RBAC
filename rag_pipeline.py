from dotenv import load_dotenv
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy.future import select
from models import Document
import os
from fastapi import APIRouter, Depends, HTTPException
from pydantic import BaseModel
from database import get_db
from auth import get_current_user
from openai import OpenAI, OpenAIError

# ‚úÖ Load environment variables securely
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    raise ValueError("‚ùå Missing OpenAI API Key. Set OPENAI_API_KEY in .env")

# ‚úÖ Initialize OpenAI Client
client = OpenAI(api_key=openai_api_key)

# ‚úÖ Initialize FastAPI Router
router = APIRouter()

# ‚úÖ Define request model
class QueryRequest(BaseModel):
    query: str

async def generate_response_with_ai(context: str, query: str):
    """
    üîπ Generate an AI-powered response based on retrieved document context.
    - context: Extracted relevant document data
    - query: User's input query
    - Returns AI-generated response
    """
    prompt = f"Based on the following context, answer the query.\n\nContext:\n{context}\n\nQuery: {query}\nAnswer:"
    
    try:
        completion = client.chat.completions.create(
            model="gpt-4o",  # ‚úÖ Ensure correct model is used
            messages=[{"role": "user", "content": prompt}]
        )
        return completion.choices[0].message.content

    except OpenAIError as e:
        print(f"‚ùå OpenAI API Error: {e}")  # ‚úÖ Debugging
        return "‚ùå Sorry, I couldn't generate a response at the moment."

@router.post("/query")
async def query_rag(
    request: QueryRequest, 
    db: AsyncSession = Depends(get_db), 
    user: dict = Depends(get_current_user)
):
    """
    üîπ AI-powered RAG Pipeline Query Handler
    - Searches for relevant documents
    - Extracts relevant content
    - Uses OpenAI to generate AI responses
    """
    try:
        # ‚úÖ Retrieve relevant document chunks
        documents = await get_relevant_chunks(db, request.query)
        
        if not documents:
            raise HTTPException(status_code=404, detail="No relevant documents found")

        # ‚úÖ Combine relevant document contents into a context string
        context = "\n".join([doc.content for doc in documents])

        # ‚úÖ Generate AI response based on retrieved context
        answer = await generate_response_with_ai(context, request.query)

        return {"query": request.query, "context": context, "answer": answer}
    
    except Exception as e:
        print(f"‚ùå Unexpected Error: {e}")  # ‚úÖ Debugging
        raise HTTPException(status_code=500, detail="Internal Server Error")

async def get_relevant_chunks(db: AsyncSession, query: str, top_k: int = 3):
    """
    üîπ Retrieve the most relevant documents based on a user query.
    - Uses SQLAlchemy to fetch data from `documents` table
    - Matches query against document content
    - Returns top_k relevant document chunks
    """
    try:
        result = await db.execute(
            select(Document)
            .filter(Document.content.contains(query))  # ‚úÖ Search for relevant content
            .limit(top_k)  # ‚úÖ Limit results
        )
        documents = result.scalars().all()
        return documents

    except Exception as e:
        print(f"‚ùå Database Query Error: {e}")  # ‚úÖ Debugging
        return []
